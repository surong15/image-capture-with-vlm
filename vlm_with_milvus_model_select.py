#!/usr/bin/env python3
"""
VLM + Milvus å‘é‡è³‡æ–™åº«æ•´åˆç‰ˆæœ¬ï¼ˆå¯é¸æ¨¡å‹ï¼‰
- æ”¯æ´ llava-phi3:latest æˆ– gemma3:1b æ–¼ Ollama
- å½±åƒç›´æ¥å„²å­˜åœ¨ Milvus
- GUI å¯é¸æ¨¡å‹
"""
import cv2
import numpy as np
from PIL import Image, ImageTk
import requests
import base64
import io
import tkinter as tk
from tkinter import ttk, scrolledtext, messagebox
from datetime import datetime
import threading
import time
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility
from sentence_transformers import SentenceTransformer
import uuid

class VLMWithMilvusModelSelect:
    def __init__(self):
        self.cap = None
        self.current_frame = None
        self.captured_frame = None
        self.is_running = False
        self.ollama_url = "http://localhost:11434"
        self.live_video_label = None
        self.captured_image_label = None
        self.update_video_flag = True
        self.is_analyzing = False
        self.current_model = "llava-phi3:latest"
        self.available_models = ["llava-phi3:latest", "gemma3:1b"]
        self.setup_gui()
        self.init_vector_db()

    def init_vector_db(self):
        try:
            connections.connect(alias="default", host='localhost', port='19530')
            self.encoder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            self.collection_name = "vlm_conversations_with_images"
            if utility.has_collection(self.collection_name):
                self.collection = Collection(self.collection_name)
            else:
                fields = [
                    FieldSchema(name="id", dtype=DataType.VARCHAR, max_length=100, is_primary=True),
                    FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=384),
                    FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=5000),
                    FieldSchema(name="question", dtype=DataType.VARCHAR, max_length=1000),
                    FieldSchema(name="answer", dtype=DataType.VARCHAR, max_length=3000),
                    FieldSchema(name="image_base64", dtype=DataType.VARCHAR, max_length=65000),
                    FieldSchema(name="image_size", dtype=DataType.VARCHAR, max_length=50),
                    FieldSchema(name="image_format", dtype=DataType.VARCHAR, max_length=20),
                    FieldSchema(name="timestamp", dtype=DataType.VARCHAR, max_length=50),
                    FieldSchema(name="date", dtype=DataType.VARCHAR, max_length=20),
                    FieldSchema(name="time", dtype=DataType.VARCHAR, max_length=20),
                    FieldSchema(name="model", dtype=DataType.VARCHAR, max_length=100),
                    FieldSchema(name="temperature", dtype=DataType.DOUBLE),
                    FieldSchema(name="conversation_type", dtype=DataType.VARCHAR, max_length=50)
                ]
                schema = CollectionSchema(fields=fields, description="VLM conversations with embedded images")
                self.collection = Collection(name=self.collection_name, schema=schema)
            try:
                index_params = {"metric_type": "COSINE", "index_type": "IVF_FLAT", "params": {"nlist": 128}}
                self.collection.create_index(field_name="vector", index_params=index_params)
            except Exception as e:
                pass
            self.collection.load()
            self.vector_db_status = "âœ… Milvus å‘é‡è³‡æ–™åº«å·²é€£æ¥"
        except Exception as e:
            self.vector_db_status = f"âŒ Milvus å‘é‡è³‡æ–™åº«é€£æ¥å¤±æ•—: {e}"
            self.collection = None

    def image_to_base64(self, frame, quality=85, max_size=800):
        try:
            pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            if max(pil_image.size) > max_size:
                ratio = max_size / max(pil_image.size)
                new_size = tuple(int(dim * ratio) for dim in pil_image.size)
                pil_image = pil_image.resize(new_size, Image.Resampling.LANCZOS)
            img_base64 = None
            current_quality = quality
            while current_quality >= 20:
                buffer = io.BytesIO()
                pil_image.save(buffer, format='JPEG', quality=current_quality)
                current_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
                if len(current_base64) <= 65000:
                    img_base64 = current_base64
                    break
                current_quality -= 10
            if img_base64 is None:
                return None, None
            return img_base64, pil_image.size
        except Exception:
            return None, None

    def base64_to_image(self, base64_str):
        try:
            image_data = base64.b64decode(base64_str)
            pil_image = Image.open(io.BytesIO(image_data))
            return pil_image
        except Exception:
            return None

    def save_conversation_to_vector_db(self, question, answer, frame_base64, image_size):
        if not self.collection:
            return
        try:
            timestamp = datetime.now()
            conversation_text = f"å•é¡Œ: {question}\nå›ç­”: {answer}"
            vector = self.encoder.encode([conversation_text])[0]
            data = [{
                "id": str(uuid.uuid4()),
                "vector": vector.tolist(),
                "content": conversation_text,
                "question": question,
                "answer": answer,
                "image_base64": frame_base64,
                "image_size": f"{image_size[0]}x{image_size[1]}" if image_size else "unknown",
                "image_format": "JPEG",
                "timestamp": timestamp.isoformat(),
                "date": timestamp.strftime("%Y-%m-%d"),
                "time": timestamp.strftime("%H:%M:%S"),
                "model": self.current_model,
                "temperature": self.temperature_var.get(),
                "conversation_type": "vlm_qa"
            }]
            self.collection.insert(data)
            self.collection.flush()
            self.log_message(f"ğŸ’¾ å°è©±å’Œå½±åƒå·²å„²å­˜åˆ° Milvus å‘é‡è³‡æ–™åº«")
        except Exception as e:
            self.log_message(f"âš ï¸ Milvus å‘é‡è³‡æ–™åº«å„²å­˜å¤±æ•—: {e}")

    def setup_gui(self):
        self.root = tk.Tk()
        self.root.title("VLM ç³»çµ± + Milvus å‘é‡è³‡æ–™åº« (æ¨¡å‹å¯é¸)")
        self.root.geometry("1200x800")
        main_frame = ttk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        image_container = ttk.Frame(main_frame)
        image_container.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(0, 10))
        live_frame = ttk.LabelFrame(image_container, text="ğŸ“¹ å³æ™‚å½±åƒ")
        live_frame.pack(fill=tk.BOTH, expand=True, pady=(0, 5))
        self.live_video_label = ttk.Label(live_frame, text="å³æ™‚ç›¸æ©Ÿç•«é¢\né»æ“Šã€Œé–‹å§‹ç›¸æ©Ÿã€å•Ÿå‹•")
        self.live_video_label.pack(expand=True, padx=10, pady=10)
        captured_frame = ttk.LabelFrame(image_container, text="ğŸ“¸ æ­£åœ¨åˆ†æçš„ç…§ç‰‡")
        captured_frame.pack(fill=tk.BOTH, expand=True, pady=(5, 0))
        self.captured_image_label = ttk.Label(captured_frame, text="å°šæœªæ‹æ”ç…§ç‰‡\né»æ“Šã€Œæ‹ç…§åˆ†æã€é–‹å§‹")
        self.captured_image_label.pack(expand=True, padx=10, pady=10)
        right_frame = ttk.Frame(main_frame, width=500)
        right_frame.pack(side=tk.RIGHT, fill=tk.BOTH, padx=(10, 0))
        right_frame.pack_propagate(False)
        status_frame = ttk.LabelFrame(right_frame, text="ç³»çµ±ç‹€æ…‹")
        status_frame.pack(fill=tk.X, pady=(0, 10))
        self.ollama_status = ttk.Label(status_frame, text="Ollama ç‹€æ…‹: æª¢æŸ¥ä¸­...")
        self.ollama_status.pack(anchor=tk.W, padx=5, pady=3)
        self.vector_db_label = ttk.Label(status_frame, text=getattr(self, 'vector_db_status', 'æª¢æŸ¥ä¸­...'))
        self.vector_db_label.pack(anchor=tk.W, padx=5, pady=3)
        camera_frame = ttk.LabelFrame(right_frame, text="ç›¸æ©Ÿæ§åˆ¶")
        camera_frame.pack(fill=tk.X, pady=(0, 10))
        camera_btn_frame = ttk.Frame(camera_frame)
        camera_btn_frame.pack(fill=tk.X, padx=5, pady=5)
        self.start_btn = ttk.Button(camera_btn_frame, text="é–‹å§‹ç›¸æ©Ÿ", command=self.start_camera)
        self.start_btn.pack(side=tk.LEFT, padx=(0, 5))
        self.stop_btn = ttk.Button(camera_btn_frame, text="åœæ­¢ç›¸æ©Ÿ", command=self.stop_camera, state=tk.DISABLED)
        self.stop_btn.pack(side=tk.LEFT, padx=(0, 5))
        self.capture_btn = ttk.Button(camera_btn_frame, text="æ‹ç…§åˆ†æ", command=self.capture_and_ask, state=tk.DISABLED)
        self.capture_btn.pack(side=tk.RIGHT)
        options_frame = ttk.LabelFrame(right_frame, text="æ¨¡å‹åƒæ•¸")
        options_frame.pack(fill=tk.X, pady=(0, 10))

        # ç¬¬ä¸€è¡Œï¼šæ¨¡å‹é¸æ“‡
        model_row = ttk.Frame(options_frame)
        model_row.pack(fill=tk.X, pady=(0, 2))
        model_label = ttk.Label(model_row, text="é¸æ“‡æ¨¡å‹:")
        model_label.pack(side=tk.LEFT, padx=(5,0))
        self.model_var = tk.StringVar()
        self.model_combobox = ttk.Combobox(model_row, textvariable=self.model_var, state="readonly", width=22)
        self.model_combobox.pack(side=tk.LEFT, padx=(5, 10))
        self.model_combobox['values'] = self.available_models
        self.model_var.set(self.current_model)
        self.model_combobox.bind("<<ComboboxSelected>>", self.on_model_selected)

        # ç¬¬äºŒè¡Œï¼šæº«åº¦èª¿æ•´
        temp_row = ttk.Frame(options_frame)
        temp_row.pack(fill=tk.X, pady=(0, 2))
        temp_label = ttk.Label(temp_row, text="Temperature (0.0-1.0):")
        temp_label.pack(side=tk.LEFT, padx=(5,0))
        self.temperature_var = tk.DoubleVar(value=0.2)
        self.temperature_scale = ttk.Scale(temp_row, from_=0.0, to=1.0, orient=tk.HORIZONTAL, variable=self.temperature_var, command=self.update_temp_label, length=120)
        self.temperature_scale.pack(side=tk.LEFT, padx=(5,0))
        self.temp_value_label = ttk.Label(temp_row, text=f"{self.temperature_var.get():.2f}", width=4)
        self.temp_value_label.pack(side=tk.LEFT, padx=(5,5))

        # å•é¡Œè¼¸å…¥å€å¡Šï¼ˆé«˜åº¦èª¿å¤§ï¼Œå­—é«”åŠ å¤§ï¼‰
        question_frame = ttk.LabelFrame(right_frame, text="å•é¡Œè¼¸å…¥")
        question_frame.pack(fill=tk.X, pady=(0, 10))
        self.question_entry = tk.Text(question_frame, height=4, wrap=tk.WORD, font=("Arial", 14))
        self.question_entry.pack(fill=tk.X, padx=5, pady=3)
        self.question_entry.insert(tk.END, "è«‹æè¿°é€™å¼µåœ–ç‰‡ã€‚")

        # Milvus å°è©±è¨˜éŒ„èˆ‡å½±åƒåŠŸèƒ½å€å¡Š
        vector_frame = ttk.LabelFrame(right_frame, text="ğŸ“š å°è©±è¨˜éŒ„èˆ‡å½±åƒ (Milvus)")
        vector_frame.pack(fill=tk.X, pady=(0, 10))
        vector_btn_frame = ttk.Frame(vector_frame)
        vector_btn_frame.pack(fill=tk.X, padx=5, pady=5)
        self.search_btn = ttk.Button(vector_btn_frame, text="æœå°‹å°è©±", command=self.search_conversations)
        self.search_btn.pack(side=tk.LEFT, padx=(0, 5))
        self.view_history_btn = ttk.Button(vector_btn_frame, text="æŸ¥çœ‹æ­·å²", command=self.view_conversation_history)
        self.view_history_btn.pack(side=tk.LEFT, padx=(0, 5))
        self.view_image_btn = ttk.Button(vector_btn_frame, text="æª¢è¦–å½±åƒ", command=self.view_image_from_history)
        self.view_image_btn.pack(side=tk.LEFT)
        search_frame = ttk.Frame(vector_frame)
        search_frame.pack(fill=tk.X, padx=5, pady=(0, 5))
        ttk.Label(search_frame, text="æœå°‹:").pack(side=tk.LEFT)
        self.search_entry = ttk.Entry(search_frame)
        self.search_entry.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(5, 0))
        self.search_entry.bind('<Return>', lambda e: self.search_conversations())
        result_frame = ttk.LabelFrame(right_frame, text="AI å›ç­”")
        result_frame.pack(fill=tk.BOTH, expand=True)
        self.result_text = scrolledtext.ScrolledText(result_frame, height=12, wrap=tk.WORD)
        self.result_text.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        self.status_label = ttk.Label(self.root, text="æº–å‚™å°±ç·’")
        self.status_label.pack(fill=tk.X, side=tk.BOTTOM, padx=10, pady=5)
        self.root.after(100, self.check_ollama_connection)

    def on_model_selected(self, event=None):
        self.current_model = self.model_var.get()
        self.log_message(f"å·²åˆ‡æ›æ¨¡å‹: {self.current_model}")

    def update_temp_label(self, value):
        self.temp_value_label.config(text=f"{float(value):.2f}")

    def check_ollama_connection(self):
        def check_in_background():
            try:
                response = requests.get(f"{self.ollama_url}/api/tags", timeout=3)
                if response.status_code == 200:
                    models = response.json().get("models", [])
                    model_names = [model.get("name", "") for model in models]
                    # ä¸ç¯©é¸ï¼Œå…¨éƒ¨é¡¯ç¤º
                    filtered = model_names
                    if filtered:
                        self.available_models = filtered
                        self.root.after(0, lambda: self.model_combobox.config(values=filtered))
                        if self.current_model not in filtered:
                            self.current_model = filtered[0]
                            self.root.after(0, lambda: self.model_var.set(filtered[0]))
                        self.root.after(0, lambda: self.ollama_status.config(text=f"âœ… Ollama å¯ç”¨: {', '.join(filtered)}", foreground="green"))
                        self.root.after(0, lambda: self.capture_btn.config(state=tk.NORMAL))
                    else:
                        self.root.after(0, lambda: self.ollama_status.config(text="âš ï¸ æ²’æœ‰å¯ç”¨æ¨¡å‹ï¼Œè«‹å…ˆä¸‹è¼‰", foreground="orange"))
                else:
                    raise Exception("æœå‹™ä¸å¯ç”¨")
            except Exception:
                self.root.after(0, lambda: self.ollama_status.config(text="âŒ Ollama æœªé‹è¡Œ", foreground="red"))
        threading.Thread(target=check_in_background, daemon=True).start()

    def start_camera(self):
        try:
            self.cap = cv2.VideoCapture(0)
            if not self.cap.isOpened():
                raise Exception("ç„¡æ³•é–‹å•Ÿç›¸æ©Ÿ")
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.is_running = True
            self.update_video_flag = True
            self.video_thread = threading.Thread(target=self.update_live_video)
            self.video_thread.daemon = True
            self.video_thread.start()
            self.start_btn.config(state=tk.DISABLED)
            self.stop_btn.config(state=tk.NORMAL)
            self.capture_btn.config(state=tk.NORMAL)
            self.status_label.config(text="ç›¸æ©Ÿå·²å•Ÿå‹•")
            self.log_message("ç›¸æ©Ÿå•Ÿå‹•æˆåŠŸ")
        except Exception as e:
            messagebox.showerror("éŒ¯èª¤", f"ç›¸æ©Ÿå•Ÿå‹•å¤±æ•—: {str(e)}")

    def stop_camera(self):
        self.is_running = False
        self.update_video_flag = False
        if self.cap:
            self.cap.release()
        self.live_video_label.config(image="", text="ç›¸æ©Ÿå·²åœæ­¢")
        self.start_btn.config(state=tk.NORMAL)
        self.stop_btn.config(state=tk.DISABLED)
        self.capture_btn.config(state=tk.DISABLED)
        self.status_label.config(text="ç›¸æ©Ÿå·²åœæ­¢")
        self.log_message("ç›¸æ©Ÿå·²åœæ­¢")

    def update_live_video(self):
        while self.is_running and self.update_video_flag:
            try:
                ret, frame = self.cap.read()
                if ret:
                    self.current_frame = frame.copy()
                    display_frame = cv2.resize(frame, (400, 300))
                    display_frame = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
                    pil_image = Image.fromarray(display_frame)
                    photo = ImageTk.PhotoImage(pil_image)
                    self.root.after(0, self._update_live_video_label, photo)
                    time.sleep(0.033)
            except Exception:
                break

    def _update_live_video_label(self, photo):
        if self.live_video_label and self.update_video_flag:
            self.live_video_label.config(image=photo, text="")
            self.live_video_label.image = photo

    def capture_and_ask(self):
        if self.current_frame is None:
            messagebox.showwarning("è­¦å‘Š", "æ²’æœ‰å¯ç”¨çš„å½±åƒ")
            return
        question = self.question_entry.get(1.0, tk.END).strip()
        if not question:
            question = "è«‹æè¿°é€™å¼µåœ–ç‰‡ã€‚"
        self.captured_frame = self.current_frame.copy()
        self.display_captured_image()
        self.is_analyzing = True
        self.status_label.config(text="AI åˆ†æä¸­...")
        self.log_message(f"å•é¡Œ: {question}")
        threading.Thread(target=self.process_with_ollama, args=(self.captured_frame.copy(), question), daemon=True).start()

    def display_captured_image(self):
        if self.captured_frame is not None:
            display_frame = cv2.resize(self.captured_frame, (400, 300))
            display_frame = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(display_frame)
            photo = ImageTk.PhotoImage(pil_image)
            self.captured_image_label.config(image=photo, text="")
            self.captured_image_label.image = photo

    def process_with_ollama(self, frame, question):
        try:
            frame_base64, image_size = self.image_to_base64(frame, quality=85, max_size=800)
            pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            if max(pil_image.size) > 512:
                ratio = 512 / max(pil_image.size)
                new_size = tuple(int(dim * ratio) for dim in pil_image.size)
                pil_image = pil_image.resize(new_size, Image.Resampling.LANCZOS)
            buffer = io.BytesIO()
            pil_image.save(buffer, format='PNG')
            img_base64_api = base64.b64encode(buffer.getvalue()).decode()
            temperature = self.temperature_var.get()
            payload = {
                "model": self.current_model,
                "prompt": question,
                "images": [img_base64_api],
                "stream": False,
                "options": {"temperature": temperature}
            }
            self.log_message(f"æ­£åœ¨å‘¼å« Ollama API (Temperature: {temperature:.2f}, Model: {self.current_model})...")
            response = requests.post(f"{self.ollama_url}/api/generate", json=payload, timeout=120)
            if response.status_code == 200:
                result = response.json()
                answer = result.get("response", "ç„¡æ³•ç²å¾—å›ç­”")
                if answer and answer.strip():
                    self.log_message(f"AI å›ç­”: {answer}")
                    if frame_base64:
                        self.save_conversation_to_vector_db(
                            question=question,
                            answer=answer,
                            frame_base64=frame_base64,
                            image_size=image_size
                        )
                else:
                    self.log_message("âš ï¸ AI å›ç­”ç‚ºç©ºï¼Œè«‹é‡è©¦")
            else:
                self.log_message(f"API éŒ¯èª¤ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
                self.log_message(f"éŒ¯èª¤å…§å®¹: {response.text}")
            self.is_analyzing = False
            self.root.after(0, lambda: self.status_label.config(text="åˆ†æå®Œæˆ"))
        except requests.exceptions.Timeout:
            self.log_message("â° è«‹æ±‚è¶…æ™‚ - LLaVA-Phi3 é¦–æ¬¡æ¨ç†éœ€è¦è¼ƒé•·æ™‚é–“")
            self.is_analyzing = False
            self.root.after(0, lambda: self.status_label.config(text="é¦–æ¬¡æ¨ç†è¶…æ™‚ï¼Œè«‹é‡è©¦"))
        except Exception as e:
            self.log_message(f"è™•ç†éŒ¯èª¤: {str(e)}")
            self.is_analyzing = False
            self.root.after(0, lambda: self.status_label.config(text="è™•ç†å¤±æ•—"))

    def log_message(self, message):
        timestamp = datetime.now().strftime("%H:%M:%S")
        formatted_message = f"[{timestamp}] {message}\n"
        self.root.after(0, self._update_text, formatted_message)

    def _update_text(self, message):
        self.result_text.insert(tk.END, message)
        self.result_text.see(tk.END)

    def run(self):
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)
        self.root.mainloop()

    def on_closing(self):
        self.stop_camera()
        try:
            connections.disconnect("default")
        except:
            pass
        self.root.destroy()

    def search_conversations(self):
        """æœå°‹æ­·å²å°è©±"""
        if not self.collection:
            messagebox.showwarning("è­¦å‘Š", "Milvus å‘é‡è³‡æ–™åº«æœªé€£æ¥")
            return
        query = self.search_entry.get().strip()
        if not query:
            messagebox.showinfo("æç¤º", "è«‹è¼¸å…¥æœå°‹é—œéµå­—")
            return
        try:
            query_vector = self.encoder.encode([query])[0]
            search_params = {
                "metric_type": "COSINE",
                "params": {"nprobe": 10}
            }
            results = self.collection.search(
                data=[query_vector.tolist()],
                anns_field="vector",
                param=search_params,
                limit=5,
                output_fields=[
                    "content", "question", "answer", "date", "time",
                    "model", "image_size", "timestamp"
                ]
            )
            if results and results[0]:
                search_results = f"\nğŸ” æœå°‹çµæœ: '{query}'\n" + "="*50 + "\n"
                for i, result in enumerate(results[0]):
                    entity = result.entity
                    search_results += f"\nçµæœ {i+1} (ç›¸ä¼¼åº¦: {result.distance:.3f}):\n"
                    search_results += f"æ™‚é–“: {entity.get('date', '')} {entity.get('time', '')}\n"
                    search_results += f"å•é¡Œ: {entity.get('question', '')}\n"
                    search_results += f"å›ç­”: {entity.get('answer', '')[:200]}...\n"
                    search_results += f"æ¨¡å‹: {entity.get('model', '')}\n"
                    search_results += f"å½±åƒå¤§å°: {entity.get('image_size', 'unknown')}\n"
                    search_results += "-" * 30 + "\n"
                self.log_message(search_results)
            else:
                self.log_message(f"ğŸ” æ²’æœ‰æ‰¾åˆ°èˆ‡ '{query}' ç›¸é—œçš„å°è©±")
        except Exception as e:
            messagebox.showerror("éŒ¯èª¤", f"æœå°‹å¤±æ•—: {e}")

    def view_conversation_history(self):
        """æŸ¥çœ‹æœ€è¿‘çš„å°è©±æ­·å²"""
        if not self.collection:
            messagebox.showwarning("è­¦å‘Š", "Milvus å‘é‡è³‡æ–™åº«æœªé€£æ¥")
            return
        try:
            total_conversations = self.collection.num_entities
            if total_conversations == 0:
                self.root.after(0, self.log_message, "ğŸ“š ç›®å‰æ²’æœ‰å°è©±è¨˜éŒ„")
                return
            limit = min(total_conversations, 1000)
            conversations = self.collection.query(
                expr="",
                output_fields=[
                    "id", "content", "question", "answer", "date", "time",
                    "model", "image_size", "timestamp"
                ],
                limit=limit
            )
            if conversations:
                history_text = f"\nğŸ“š æœ€è¿‘çš„å°è©±æ­·å² (å…± {total_conversations} å€‹å°è©±)\n" + "="*60 + "\n"
                conversations.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
                for i, conversation in enumerate(conversations[:10]):
                    history_text += f"\nå°è©± {i+1}:\n"
                    history_text += f"æ™‚é–“: {conversation.get('date', '')} {conversation.get('time', '')}\n"
                    history_text += f"å•é¡Œ: {conversation.get('question', '')}\n"
                    history_text += f"å›ç­”: {conversation.get('answer', '')[:150]}...\n"
                    history_text += f"æ¨¡å‹: {conversation.get('model', '')}\n"
                    history_text += f"å½±åƒ: {conversation.get('image_size', '')} JPEG\n"
                    history_text += f"ID: {conversation.get('id', '')}\n"
                    history_text += "-" * 40 + "\n"
                self.log_message(history_text)
            else:
                self.log_message("ğŸ“š ç›®å‰æ²’æœ‰å°è©±è¨˜éŒ„")
        except Exception as e:
            messagebox.showerror("éŒ¯èª¤", f"æŸ¥çœ‹æ­·å²å¤±æ•—: {e}")

    def view_image_from_history(self):
        """å¾æ­·å²è¨˜éŒ„ä¸­æª¢è¦–å½±åƒ"""
        if not self.collection:
            messagebox.showwarning("è­¦å‘Š", "Milvus å‘é‡è³‡æ–™åº«æœªé€£æ¥")
            return
        dialog = tk.Toplevel(self.root)
        dialog.title("æª¢è¦–æ­·å²å½±åƒ")
        dialog.geometry("400x200")
        ttk.Label(dialog, text="è«‹è¼¸å…¥è¦æª¢è¦–çš„å°è©±ç·¨è™Ÿ (1-10):").pack(pady=10)
        entry = ttk.Entry(dialog, width=10)
        entry.pack(pady=5)
        def on_submit():
            try:
                index = int(entry.get()) - 1
                if index < 0:
                    raise ValueError("ç·¨è™Ÿå¿…é ˆå¤§æ–¼0")
                self._fetch_and_display_image(index)
            except ValueError:
                messagebox.showerror("éŒ¯èª¤", "è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—")
            except Exception as e:
                messagebox.showerror("éŒ¯èª¤", f"æª¢è¦–å½±åƒå¤±æ•—: {e}")
        ttk.Button(dialog, text="æª¢è¦–å½±åƒ", command=on_submit).pack(pady=10)
        ttk.Button(dialog, text="å–æ¶ˆ", command=dialog.destroy).pack()

    def _fetch_and_display_image(self, index):
        try:
            num_entities = self.collection.num_entities
            if num_entities == 0:
                self.root.after(0, lambda: messagebox.showerror("éŒ¯èª¤", "è³‡æ–™åº«ä¸­æ²’æœ‰å°è©±è¨˜éŒ„"))
                return
            limit = min(num_entities, 1000)
            conversations = self.collection.query(
                expr="",
                output_fields=[
                    "id", "question", "answer", "date", "time",
                    "image_base64", "timestamp"
                ],
                limit=limit
            )
            if conversations and index < len(conversations):
                conversations.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
                selected_conversation = conversations[index]
                self.root.after(0, self._show_image_window, selected_conversation, index)
            else:
                self.root.after(0, lambda: messagebox.showerror("éŒ¯èª¤", "å°è©±ç·¨è™Ÿä¸å­˜åœ¨"))
        except Exception as e:
            self.root.after(0, lambda: messagebox.showerror("éŒ¯èª¤", f"æª¢è¦–å½±åƒå¤±æ•—: {e}"))

    def _show_image_window(self, conversation_data, index):
        image_base64 = conversation_data.get('image_base64')
        if image_base64:
            pil_image = self.base64_to_image(image_base64)
            if pil_image:
                img_window = tk.Toplevel(self.root)
                img_window.title(f"æ­·å²å½±åƒ - å°è©± {index + 1}")
                display_size = (600, 450)
                pil_image.thumbnail(display_size, Image.Resampling.LANCZOS)
                photo = ImageTk.PhotoImage(pil_image)
                img_label = ttk.Label(img_window, image=photo)
                img_label.pack(padx=10, pady=10)
                img_label.image = photo
                info_text = f"""æ™‚é–“: {conversation_data.get('date')} {conversation_data.get('time')}
å•é¡Œ: {conversation_data.get('question', '')}
å›ç­”: {conversation_data.get('answer', '')[:100]}..."""
                info_label = ttk.Label(img_window, text=info_text, wraplength=580)
                info_label.pack(padx=10, pady=5)
            else:
                messagebox.showerror("éŒ¯èª¤", "ç„¡æ³•è¼‰å…¥å½±åƒ")
        else:
            messagebox.showwarning("è­¦å‘Š", "è©²å°è©±æ²’æœ‰å½±åƒè³‡æ–™")

def main():
    print("VLM ç³»çµ± + Milvus å‘é‡è³‡æ–™åº« (æ¨¡å‹å¯é¸)")
    print("=" * 50)
    print("âœ¨ æ”¯æ´ LLaVA-Phi3:latest èˆ‡ Gemma3:1b")
    print("ğŸ–¼ï¸ å½±åƒç›´æ¥å„²å­˜åœ¨ Milvus å‘é‡è³‡æ–™åº«ä¸­")
    print("ğŸ” æ”¯æ´å°è©±æœå°‹å’Œå½±åƒæª¢è¦–")
    print("ğŸŒ æ”¯æ´ä¸­è‹±æ–‡å•ç­”")
    print("\nğŸ“¦ éœ€è¦çš„æœå‹™:")
    print("1. ollama pull llava-phi3:latest")
    print("2. ollama pull gemma3:1b")
    print("3. docker run -p 19530:19530 -p 9091:9091 milvusdb/milvus:latest")
    print("4. docker run -p 8000:3000 -e MILVUS_URL=localhost:19530 zilliz/attu:latest")
    print("=" * 50)
    try:
        app = VLMWithMilvusModelSelect()
        app.run()
    except KeyboardInterrupt:
        print("\nç¨‹å¼å·²åœæ­¢")

if __name__ == "__main__":
    main() 
#!/usr/bin/env python3
"""
VLM + å‘é‡è³‡æ–™åº«æ•´åˆç‰ˆæœ¬
å½±åƒç›´æ¥å„²å­˜åœ¨ Qdrant å‘é‡è³‡æ–™åº«ä¸­ï¼Œè€Œä¸æ˜¯å„²å­˜åœ¨é›»è…¦ä¸Š
DB = vlm_conversations_with_images
"""

import cv2
import numpy as np
from PIL import Image, ImageTk
import requests
import base64
import io
import json
import tkinter as tk
from tkinter import ttk, scrolledtext, messagebox
from datetime import datetime
import threading
import time
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
from sentence_transformers import SentenceTransformer
import uuid
import os

class VLMWithEmbeddedImages:
    def __init__(self):
        self.cap = None
        self.current_frame = None
        self.captured_frame = None
        self.is_running = False
        self.ollama_url = "http://localhost:11434"
        self.live_video_label = None
        self.captured_image_label = None
        self.update_video_flag = True
        self.is_analyzing = False
        self.current_model = None
        
        self.setup_gui()
        self.init_vector_db()
    
    def init_vector_db(self):
        """åˆå§‹åŒ–å‘é‡è³‡æ–™åº«"""
        try:
            print("ğŸ”— é€£æ¥å‘é‡è³‡æ–™åº«...")
            self.qdrant_client = QdrantClient("localhost", port=6333)
            self.encoder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            
            # å»ºç«‹VLMå°ˆç”¨é›†åˆ
            self.vlm_collection = "vlm_conversations_with_images"
            
            # æª¢æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨å‰‡å»ºç«‹
            collections = self.qdrant_client.get_collections()
            collection_names = [c.name for c in collections.collections]
            
            if self.vlm_collection not in collection_names:
                self.qdrant_client.create_collection(
                    collection_name=self.vlm_collection,
                    vectors_config=VectorParams(size=384, distance=Distance.COSINE)
                )
                print(f"âœ… å»ºç«‹é›†åˆ: {self.vlm_collection}")
            else:
                print(f"â„¹ï¸ é›†åˆå·²å­˜åœ¨: {self.vlm_collection}")
            
            self.vector_db_status = "âœ… å‘é‡è³‡æ–™åº«å·²é€£æ¥"
            print("âœ… å‘é‡è³‡æ–™åº«åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ å‘é‡è³‡æ–™åº«åˆå§‹åŒ–å¤±æ•—: {e}")
            self.vector_db_status = "âŒ å‘é‡è³‡æ–™åº«é€£æ¥å¤±æ•—"
            self.qdrant_client = None
    
    def image_to_base64(self, frame, quality=85, max_size=800):
        """å°‡å½±åƒè½‰æ›ç‚º base64 å­—ä¸²ç”¨æ–¼å„²å­˜"""
        try:
            # è½‰æ›ç‚º PIL å½±åƒ
            pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            
            # ç¸®æ”¾å½±åƒä»¥ç¯€çœç©ºé–“ï¼ˆä¿æŒç¸±æ©«æ¯”ï¼‰
            if max(pil_image.size) > max_size:
                ratio = max_size / max(pil_image.size)
                new_size = tuple(int(dim * ratio) for dim in pil_image.size)
                pil_image = pil_image.resize(new_size, Image.Resampling.LANCZOS)
            
            # è½‰æ›ç‚º base64
            buffer = io.BytesIO()
            pil_image.save(buffer, format='JPEG', quality=quality)
            img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            return img_base64, pil_image.size
            
        except Exception as e:
            print(f"âŒ å½±åƒè½‰æ›å¤±æ•—: {e}")
            return None, None
    
    def base64_to_image(self, base64_str):
        """å°‡ base64 å­—ä¸²è½‰æ›å›å½±åƒ"""
        try:
            # è§£ç¢¼ base64
            image_data = base64.b64decode(base64_str)
            
            # è½‰æ›ç‚º PIL å½±åƒ
            pil_image = Image.open(io.BytesIO(image_data))
            
            return pil_image
            
        except Exception as e:
            print(f"âŒ base64 è½‰å½±åƒå¤±æ•—: {e}")
            return None
    
    def save_conversation_to_vector_db(self, question, answer, frame_base64, image_size, metadata=None):
        """å°‡å°è©±å’Œå½±åƒå„²å­˜åˆ°å‘é‡è³‡æ–™åº«"""
        if not self.qdrant_client:
            print("âš ï¸ å‘é‡è³‡æ–™åº«æœªé€£æ¥ï¼Œè·³éå„²å­˜")
            return
        
        try:
            timestamp = datetime.now()
            
            # å»ºç«‹åŒ…å«å®Œæ•´å°è©±çš„æ–‡æœ¬
            conversation_text = f"å•é¡Œ: {question}\nå›ç­”: {answer}"
            
            # å»ºç«‹è©³ç´°çš„å…ƒæ•¸æ“š
            conversation_metadata = {
                "question": question,
                "answer": answer,
                "image_base64": frame_base64,  # ğŸ”¥ é—œéµï¼šå½±åƒç›´æ¥å„²å­˜ç‚º base64
                "image_size": f"{image_size[0]}x{image_size[1]}" if image_size else "unknown",
                "image_format": "JPEG",
                "timestamp": timestamp.isoformat(),
                "date": timestamp.strftime("%Y-%m-%d"),
                "time": timestamp.strftime("%H:%M:%S"),
                "model": self.current_model or "unknown",
                "temperature": self.temperature_var.get(),
                "conversation_type": "vlm_qa"
            }
            
            # åŠ å…¥é¡å¤–çš„å…ƒæ•¸æ“š
            if metadata:
                conversation_metadata.update(metadata)
            
            # å°‡å°è©±æ–‡æœ¬å‘é‡åŒ–
            vector = self.encoder.encode([conversation_text])[0]
            
            # å»ºç«‹é»æ•¸æ“š
            point = PointStruct(
                id=str(uuid.uuid4()),
                vector=vector.tolist(),
                payload={
                    "content": conversation_text,
                    **conversation_metadata
                }
            )
            
            # ä¸Šå‚³åˆ° Qdrant
            self.qdrant_client.upsert(
                collection_name=self.vlm_collection,
                points=[point]
            )
            
            self.log_message(f"ğŸ’¾ å°è©±å’Œå½±åƒå·²å„²å­˜åˆ°å‘é‡è³‡æ–™åº«")
            
            # è¨ˆç®—å„²å­˜å¤§å°
            image_size_kb = len(frame_base64) * 3 / 4 / 1024  # base64 å¤§å°ä¼°ç®—
            print(f"âœ… å°è©±å„²å­˜æˆåŠŸï¼Œå½±åƒå¤§å°: {image_size_kb:.1f} KB")
            
        except Exception as e:
            print(f"âŒ å„²å­˜å°è©±å¤±æ•—: {e}")
            self.log_message(f"âš ï¸ å‘é‡è³‡æ–™åº«å„²å­˜å¤±æ•—: {e}")
    
    def search_conversations(self):
        """æœå°‹æ­·å²å°è©±"""
        if not self.qdrant_client:
            messagebox.showwarning("è­¦å‘Š", "å‘é‡è³‡æ–™åº«æœªé€£æ¥")
            return
        
        query = self.search_entry.get().strip()
        if not query:
            messagebox.showinfo("æç¤º", "è«‹è¼¸å…¥æœå°‹é—œéµå­—")
            return
        
        try:
            # å°‡æœå°‹æŸ¥è©¢å‘é‡åŒ–
            query_vector = self.encoder.encode([query])[0]
            
            # åœ¨å‘é‡è³‡æ–™åº«ä¸­æœå°‹
            results = self.qdrant_client.search(
                collection_name=self.vlm_collection,
                query_vector=query_vector.tolist(),
                limit=5
            )
            
            if results:
                search_results = f"\nğŸ” æœå°‹çµæœ: '{query}'\n" + "="*50 + "\n"
                
                for i, result in enumerate(results):
                    payload = result.payload
                    search_results += f"\nçµæœ {i+1} (ç›¸ä¼¼åº¦: {result.score:.3f}):\n"
                    search_results += f"æ™‚é–“: {payload.get('date', '')} {payload.get('time', '')}\n"
                    search_results += f"å•é¡Œ: {payload.get('question', '')}\n"
                    search_results += f"å›ç­”: {payload.get('answer', '')[:200]}...\n"
                    search_results += f"æ¨¡å‹: {payload.get('model', '')}\n"
                    search_results += f"å½±åƒå¤§å°: {payload.get('image_size', 'unknown')}\n"
                    search_results += "-" * 30 + "\n"
                
                self.log_message(search_results)
            else:
                self.log_message(f"ğŸ” æ²’æœ‰æ‰¾åˆ°èˆ‡ '{query}' ç›¸é—œçš„å°è©±")
                
        except Exception as e:
            messagebox.showerror("éŒ¯èª¤", f"æœå°‹å¤±æ•—: {e}")
    
    def view_conversation_history(self):
        """æŸ¥çœ‹æœ€è¿‘çš„å°è©±æ­·å²"""
        if not self.qdrant_client:
            messagebox.showwarning("è­¦å‘Š", "å‘é‡è³‡æ–™åº«æœªé€£æ¥")
            return
        
        try:
            # ç²å–é›†åˆè³‡è¨Š
            collection_info = self.qdrant_client.get_collection(self.vlm_collection)
            total_conversations = collection_info.vectors_count
            
            # ä½¿ç”¨æ»¾å‹•æœå°‹ç²å–æœ€è¿‘çš„å°è©±
            from qdrant_client.models import ScrollRequest
            
            scroll_result = self.qdrant_client.scroll(
                collection_name=self.vlm_collection,
                limit=10,
                with_payload=True,
                with_vectors=False
            )
            
            if scroll_result[0]:  # scroll_result = (points, next_page_offset)
                history_text = f"\nğŸ“š æœ€è¿‘çš„å°è©±æ­·å² (å…± {total_conversations} å€‹å°è©±)\n" + "="*60 + "\n"
                
                # æŒ‰æ™‚é–“æ’åº
                conversations = scroll_result[0]
                conversations.sort(key=lambda x: x.payload.get('timestamp', ''), reverse=True)
                
                for i, point in enumerate(conversations[:10]):
                    payload = point.payload
                    history_text += f"\nå°è©± {i+1}:\n"
                    history_text += f"æ™‚é–“: {payload.get('date', '')} {payload.get('time', '')}\n"
                    history_text += f"å•é¡Œ: {payload.get('question', '')}\n"
                    history_text += f"å›ç­”: {payload.get('answer', '')[:150]}...\n"
                    history_text += f"æ¨¡å‹: {payload.get('model', '')}\n"
                    history_text += f"å½±åƒ: {payload.get('image_size', '')} {payload.get('image_format', '')}\n"
                    history_text += "-" * 40 + "\n"
                
                self.log_message(history_text)
            else:
                self.log_message("ğŸ“š ç›®å‰æ²’æœ‰å°è©±è¨˜éŒ„")
                
        except Exception as e:
            messagebox.showerror("éŒ¯èª¤", f"æŸ¥çœ‹æ­·å²å¤±æ•—: {e}")
    
    def view_image_from_history(self):
        """å¾æ­·å²è¨˜éŒ„ä¸­æª¢è¦–å½±åƒ"""
        if not self.qdrant_client:
            messagebox.showwarning("è­¦å‘Š", "å‘é‡è³‡æ–™åº«æœªé€£æ¥")
            return
        
        # ç°¡å–®çš„å°è©±IDè¼¸å…¥è¦–çª—
        dialog = tk.Toplevel(self.root)
        dialog.title("æª¢è¦–æ­·å²å½±åƒ")
        dialog.geometry("400x200")
        
        ttk.Label(dialog, text="è«‹è¼¸å…¥è¦æª¢è¦–çš„å°è©±ç·¨è™Ÿ (1-10):").pack(pady=10)
        
        entry = ttk.Entry(dialog, width=10)
        entry.pack(pady=5)
        
        def show_image():
            try:
                index = int(entry.get()) - 1
                if index < 0:
                    raise ValueError("ç·¨è™Ÿå¿…é ˆå¤§æ–¼0")
                
                # ç²å–å°è©±è³‡æ–™
                scroll_result = self.qdrant_client.scroll(
                    collection_name=self.vlm_collection,
                    limit=10,
                    with_payload=True,
                    with_vectors=False
                )
                
                if scroll_result[0] and index < len(scroll_result[0]):
                    conversations = scroll_result[0]
                    conversations.sort(key=lambda x: x.payload.get('timestamp', ''), reverse=True)
                    
                    selected_conversation = conversations[index]
                    image_base64 = selected_conversation.payload.get('image_base64')
                    
                    if image_base64:
                        # è½‰æ›ä¸¦é¡¯ç¤ºå½±åƒ
                        pil_image = self.base64_to_image(image_base64)
                        if pil_image:
                            # å‰µå»ºæ–°è¦–çª—é¡¯ç¤ºå½±åƒ
                            img_window = tk.Toplevel(self.root)
                            img_window.title(f"æ­·å²å½±åƒ - å°è©± {index+1}")
                            
                            # èª¿æ•´å½±åƒå¤§å°ä»¥é©åˆè¦–çª—
                            display_size = (600, 450)
                            pil_image.thumbnail(display_size, Image.Resampling.LANCZOS)
                            
                            photo = ImageTk.PhotoImage(pil_image)
                            img_label = ttk.Label(img_window, image=photo)
                            img_label.pack(padx=10, pady=10)
                            img_label.image = photo  # ä¿æŒå¼•ç”¨
                            
                            # é¡¯ç¤ºç›¸é—œè³‡è¨Š
                            info_text = f"""æ™‚é–“: {selected_conversation.payload.get('date')} {selected_conversation.payload.get('time')}
å•é¡Œ: {selected_conversation.payload.get('question', '')}
å›ç­”: {selected_conversation.payload.get('answer', '')[:100]}..."""
                            
                            info_label = ttk.Label(img_window, text=info_text, wraplength=580)
                            info_label.pack(padx=10, pady=5)
                        else:
                            messagebox.showerror("éŒ¯èª¤", "ç„¡æ³•è¼‰å…¥å½±åƒ")
                    else:
                        messagebox.showwarning("è­¦å‘Š", "è©²å°è©±æ²’æœ‰å½±åƒè³‡æ–™")
                else:
                    messagebox.showerror("éŒ¯èª¤", "å°è©±ç·¨è™Ÿä¸å­˜åœ¨")
                    
                dialog.destroy()
                
            except ValueError:
                messagebox.showerror("éŒ¯èª¤", "è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—")
            except Exception as e:
                messagebox.showerror("éŒ¯èª¤", f"æª¢è¦–å½±åƒå¤±æ•—: {e}")
        
        ttk.Button(dialog, text="æª¢è¦–å½±åƒ", command=show_image).pack(pady=10)
        ttk.Button(dialog, text="å–æ¶ˆ", command=dialog.destroy).pack()

    def setup_gui(self):
        """è¨­ç½®åœ–å½¢ç•Œé¢"""
        self.root = tk.Tk()
        self.root.title("VLM ç³»çµ± + å‘é‡è³‡æ–™åº« (å½±åƒå…§åµŒç‰ˆ)")
        self.root.geometry("1400x900")
        
        # ä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # å·¦å´ - å½±åƒé¡¯ç¤ºå€åŸŸ
        image_container = ttk.Frame(main_frame)
        image_container.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(0, 10))
        
        # å³æ™‚å½±åƒå€åŸŸ
        live_frame = ttk.LabelFrame(image_container, text="ğŸ“¹ å³æ™‚å½±åƒ")
        live_frame.pack(fill=tk.BOTH, expand=True, pady=(0, 5))
        
        self.live_video_label = ttk.Label(live_frame, text="å³æ™‚ç›¸æ©Ÿç•«é¢\né»æ“Šã€Œé–‹å§‹ç›¸æ©Ÿã€å•Ÿå‹•")
        self.live_video_label.pack(expand=True, padx=10, pady=10)
        
        # åˆ†æç…§ç‰‡å€åŸŸ
        captured_frame = ttk.LabelFrame(image_container, text="ğŸ“¸ æ­£åœ¨åˆ†æçš„ç…§ç‰‡")
        captured_frame.pack(fill=tk.BOTH, expand=True, pady=(5, 0))
        
        self.captured_image_label = ttk.Label(captured_frame, text="å°šæœªæ‹æ”ç…§ç‰‡\né»æ“Šã€Œæ‹ç…§åˆ†æã€é–‹å§‹")
        self.captured_image_label.pack(expand=True, padx=10, pady=10)
        
        # å³å´ - æ§åˆ¶å’Œçµæœå€åŸŸ
        right_frame = ttk.Frame(main_frame, width=500)
        right_frame.pack(side=tk.RIGHT, fill=tk.BOTH, padx=(10, 0))
        right_frame.pack_propagate(False)
        
        # ç³»çµ±ç‹€æ…‹
        status_frame = ttk.LabelFrame(right_frame, text="ç³»çµ±ç‹€æ…‹")
        status_frame.pack(fill=tk.X, pady=(0, 10))
        
        self.ollama_status = ttk.Label(status_frame, text="Ollama ç‹€æ…‹: æª¢æŸ¥ä¸­...")
        self.ollama_status.pack(anchor=tk.W, padx=5, pady=3)
        
        # å‘é‡è³‡æ–™åº«ç‹€æ…‹
        self.vector_db_label = ttk.Label(status_frame, text=getattr(self, 'vector_db_status', 'æª¢æŸ¥ä¸­...'))
        self.vector_db_label.pack(anchor=tk.W, padx=5, pady=3)
        
        # ç›¸æ©Ÿæ§åˆ¶
        camera_frame = ttk.LabelFrame(right_frame, text="ç›¸æ©Ÿæ§åˆ¶")
        camera_frame.pack(fill=tk.X, pady=(0, 10))
        
        camera_btn_frame = ttk.Frame(camera_frame)
        camera_btn_frame.pack(fill=tk.X, padx=5, pady=5)
        
        self.start_btn = ttk.Button(camera_btn_frame, text="é–‹å§‹ç›¸æ©Ÿ", command=self.start_camera)
        self.start_btn.pack(side=tk.LEFT, padx=(0, 5))
        
        self.stop_btn = ttk.Button(camera_btn_frame, text="åœæ­¢ç›¸æ©Ÿ", command=self.stop_camera, state=tk.DISABLED)
        self.stop_btn.pack(side=tk.LEFT, padx=(0, 5))
        
        self.capture_btn = ttk.Button(camera_btn_frame, text="æ‹ç…§åˆ†æ", command=self.capture_and_ask, state=tk.DISABLED)
        self.capture_btn.pack(side=tk.RIGHT)
        
        # å•é¡Œè¼¸å…¥
        question_frame = ttk.LabelFrame(right_frame, text="å•é¡Œè¼¸å…¥")
        question_frame.pack(fill=tk.X, pady=(0, 10))
        
        self.question_entry = tk.Text(question_frame, height=3, wrap=tk.WORD)
        self.question_entry.pack(fill=tk.X, padx=5, pady=5)
        self.question_entry.insert(tk.END, "è«‹æè¿°é€™å¼µåœ–ç‰‡ã€‚")
        
        # å¿«é€Ÿå•é¡Œ
        quick_frame = ttk.Frame(question_frame)
        quick_frame.pack(fill=tk.X, padx=5, pady=(5, 0))
        
        quick_questions = [
            ("æœ‰ä»€éº¼ï¼Ÿ", "é€™å¼µåœ–ç‰‡è£¡æœ‰ä»€éº¼ï¼Ÿ"),
            ("è©³ç´°æè¿°", "è«‹è©³ç´°æè¿°é€™å¼µåœ–ç‰‡çš„å…§å®¹ã€‚"),
            ("What's this?", "What do you see in this image?"),
            ("é¡è‰²ï¼Ÿ", "ä¸»è¦æœ‰ä»€éº¼é¡è‰²ï¼Ÿ"),
            ("å¹¾å€‹äººï¼Ÿ", "åœ–ç‰‡ä¸­æœ‰å¹¾å€‹äººï¼Ÿ"),
            ("Describe", "Describe this image in detail.")
        ]
        
        for i, (short_text, full_question) in enumerate(quick_questions):
            btn = ttk.Button(quick_frame, text=short_text, 
                           command=lambda q=full_question: self.set_question(q))
            btn.grid(row=i//3, column=i%3, padx=2, pady=2, sticky="ew")
        
        for i in range(3):
            quick_frame.columnconfigure(i, weight=1)
        
        # ğŸ”¥ æ–°å¢ï¼šå‘é‡è³‡æ–™åº«æ§åˆ¶å€åŸŸ
        vector_frame = ttk.LabelFrame(right_frame, text="ğŸ“š å°è©±è¨˜éŒ„èˆ‡å½±åƒ")
        vector_frame.pack(fill=tk.X, pady=(0, 10))
        
        vector_btn_frame = ttk.Frame(vector_frame)
        vector_btn_frame.pack(fill=tk.X, padx=5, pady=5)
        
        self.search_btn = ttk.Button(vector_btn_frame, text="æœå°‹å°è©±", command=self.search_conversations)
        self.search_btn.pack(side=tk.LEFT, padx=(0, 5))
        
        self.view_history_btn = ttk.Button(vector_btn_frame, text="æŸ¥çœ‹æ­·å²", command=self.view_conversation_history)
        self.view_history_btn.pack(side=tk.LEFT, padx=(0, 5))
        
        self.view_image_btn = ttk.Button(vector_btn_frame, text="æª¢è¦–å½±åƒ", command=self.view_image_from_history)
        self.view_image_btn.pack(side=tk.LEFT)
        
        # æœå°‹æ¡†
        search_frame = ttk.Frame(vector_frame)
        search_frame.pack(fill=tk.X, padx=5, pady=(0, 5))
        
        ttk.Label(search_frame, text="æœå°‹:").pack(side=tk.LEFT)
        self.search_entry = ttk.Entry(search_frame)
        self.search_entry.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(5, 0))
        self.search_entry.bind('<Return>', lambda e: self.search_conversations())
        
        # çµæœé¡¯ç¤º
        result_frame = ttk.LabelFrame(right_frame, text="AI å›ç­”")
        result_frame.pack(fill=tk.BOTH, expand=True)
        
        self.result_text = scrolledtext.ScrolledText(result_frame, height=12, wrap=tk.WORD)
        self.result_text.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # æ¨¡å‹åƒæ•¸
        options_frame = ttk.LabelFrame(right_frame, text="æ¨¡å‹åƒæ•¸")
        options_frame.pack(fill=tk.X, pady=(0, 10))
        
        temp_label = ttk.Label(options_frame, text="Temperature (0.0-1.0):")
        temp_label.pack(side=tk.LEFT, padx=(5,0))
        
        self.temperature_var = tk.DoubleVar(value=0.2)
        
        self.temp_value_label = ttk.Label(options_frame, text=f"{self.temperature_var.get():.2f}", width=4)
        self.temp_value_label.pack(side=tk.RIGHT, padx=(0,5))

        self.temperature_scale = ttk.Scale(options_frame, from_=0.0, to=1.0, 
                                          orient=tk.HORIZONTAL, variable=self.temperature_var,
                                          command=self.update_temp_label)
        self.temperature_scale.pack(fill=tk.X, expand=True, padx=5)

        # ç‹€æ…‹åˆ—
        self.status_label = ttk.Label(self.root, text="æº–å‚™å°±ç·’")
        self.status_label.pack(fill=tk.X, side=tk.BOTTOM, padx=10, pady=5)
        
        # æ›´æ–°å‘é‡è³‡æ–™åº«ç‹€æ…‹é¡¯ç¤º
        if hasattr(self, 'vector_db_status'):
            self.vector_db_label.config(text=self.vector_db_status)
        
        # å»¶é²å•Ÿå‹• Ollama é€£ç·šæª¢æŸ¥
        self.root.after(100, self.check_ollama_connection)
    
    def set_question(self, question):
        """è¨­ç½®å•é¡Œ"""
        self.question_entry.delete(1.0, tk.END)
        self.question_entry.insert(tk.END, question)
    
    def update_temp_label(self, value):
        """æ›´æ–°æº«åº¦é¡¯ç¤ºæ¨™ç±¤"""
        self.temp_value_label.config(text=f"{float(value):.2f}")
    
    def check_ollama_connection(self):
        """æª¢æŸ¥ Ollama é€£æ¥ç‹€æ…‹"""
        def check_in_background():
            try:
                response = requests.get(f"{self.ollama_url}/api/tags", timeout=3)
                if response.status_code == 200:
                    models = response.json().get("models", [])
                    model_names = [model.get("name", "") for model in models]
                    
                    target_model = "llava-phi3:latest"
                    
                    if any(target_model in name for name in model_names):
                        self.current_model = target_model
                        self.root.after(0, lambda: self.ollama_status.config(
                            text="âœ… Ollama + LLaVA-Phi3 å¯ç”¨", foreground="green"))
                        self.root.after(0, lambda: self.capture_btn.config(state=tk.NORMAL))
                        self.log_message(f"ä½¿ç”¨æ¨¡å‹: {self.current_model}")
                    else:
                        phi3_models = [name for name in model_names if "llava-phi3" in name]
                        if phi3_models:
                            self.current_model = phi3_models[0]
                            self.root.after(0, lambda: self.ollama_status.config(
                                text=f"âœ… Ollama + {self.current_model} å¯ç”¨", foreground="green"))
                            self.root.after(0, lambda: self.capture_btn.config(state=tk.NORMAL))
                            self.log_message(f"ä½¿ç”¨æ¨¡å‹: {self.current_model}")
                        else:
                            self.root.after(0, lambda: self.ollama_status.config(
                                text="âš ï¸ éœ€è¦å®‰è£ LLaVA-Phi3", foreground="orange"))
                            self.suggest_install_phi3()
                else:
                    raise Exception("æœå‹™ä¸å¯ç”¨")
                    
            except Exception:
                self.root.after(0, lambda: self.ollama_status.config(
                    text="âŒ Ollama æœªé‹è¡Œ", foreground="red"))
                self.log_message("è«‹åŸ·è¡Œ: ollama serve")
        
        threading.Thread(target=check_in_background, daemon=True).start()
    
    def suggest_install_phi3(self):
        """å»ºè­°å®‰è£ LLaVA-Phi3"""
        message = """éœ€è¦å®‰è£ LLaVA-Phi3 æ¨¡å‹ï¼

è«‹åœ¨çµ‚ç«¯åŸ·è¡Œï¼š
ollama pull llava-phi3:latest

LLaVA-Phi3 ç‰¹è‰²ï¼š
âœ¨ åŸºæ–¼ Microsoft Phi-3ï¼Œæ•ˆèƒ½å„ªç§€
ğŸ’¾ è¨˜æ†¶é«”éœ€æ±‚è¼ƒä½ï¼Œé©åˆ 8GB MacBook
ğŸš€ æ¨ç†é€Ÿåº¦å¿«
ğŸŒ æ”¯æ´å¤šèªè¨€å›ç­”

å®‰è£å®Œæˆå¾Œé‡æ–°å•Ÿå‹•ç¨‹å¼ã€‚"""
        
        self.log_message(message)
    
    def start_camera(self):
        """é–‹å§‹ç›¸æ©Ÿ"""
        try:
            self.cap = cv2.VideoCapture(0)
            if not self.cap.isOpened():
                raise Exception("ç„¡æ³•é–‹å•Ÿç›¸æ©Ÿ")
            
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            
            self.is_running = True
            self.update_video_flag = True
            
            self.video_thread = threading.Thread(target=self.update_live_video)
            self.video_thread.daemon = True
            self.video_thread.start()
            
            self.start_btn.config(state=tk.DISABLED)
            self.stop_btn.config(state=tk.NORMAL)
            self.capture_btn.config(state=tk.NORMAL)
            
            self.status_label.config(text="ç›¸æ©Ÿå·²å•Ÿå‹•")
            self.log_message("ç›¸æ©Ÿå•Ÿå‹•æˆåŠŸ")
            
        except Exception as e:
            messagebox.showerror("éŒ¯èª¤", f"ç›¸æ©Ÿå•Ÿå‹•å¤±æ•—: {str(e)}")
    
    def stop_camera(self):
        """åœæ­¢ç›¸æ©Ÿ"""
        self.is_running = False
        self.update_video_flag = False
        
        if self.cap:
            self.cap.release()
        
        self.live_video_label.config(image="", text="ç›¸æ©Ÿå·²åœæ­¢")
        
        self.start_btn.config(state=tk.NORMAL)
        self.stop_btn.config(state=tk.DISABLED)
        self.capture_btn.config(state=tk.DISABLED)
        
        self.status_label.config(text="ç›¸æ©Ÿå·²åœæ­¢")
        self.log_message("ç›¸æ©Ÿå·²åœæ­¢")
    
    def update_live_video(self):
        """æ›´æ–°å³æ™‚å½±åƒ"""
        while self.is_running and self.update_video_flag:
            try:
                ret, frame = self.cap.read()
                if ret:
                    self.current_frame = frame.copy()
                    
                    display_frame = cv2.resize(frame, (400, 300))
                    display_frame = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
                    
                    pil_image = Image.fromarray(display_frame)
                    photo = ImageTk.PhotoImage(pil_image)
                    
                    self.root.after(0, self._update_live_video_label, photo)
                    
                    time.sleep(0.033)  # 30 FPS
                    
            except Exception as e:
                print(f"å½±åƒæ›´æ–°éŒ¯èª¤: {e}")
                break
    
    def _update_live_video_label(self, photo):
        """æ›´æ–°å³æ™‚å½±åƒæ¨™ç±¤"""
        if self.live_video_label and self.update_video_flag:
            self.live_video_label.config(image=photo, text="")
            self.live_video_label.image = photo
    
    def capture_and_ask(self):
        """æ‹ç…§ä¸¦æå•"""
        if self.current_frame is None:
            messagebox.showwarning("è­¦å‘Š", "æ²’æœ‰å¯ç”¨çš„å½±åƒ")
            return
        
        question = self.question_entry.get(1.0, tk.END).strip()
        if not question:
            question = "è«‹æè¿°é€™å¼µåœ–ç‰‡ã€‚"
        
        self.captured_frame = self.current_frame.copy()
        self.display_captured_image()
        
        self.is_analyzing = True
        self.status_label.config(text="AI åˆ†æä¸­...")
        
        self.log_message(f"å•é¡Œ: {question}")
        
        threading.Thread(target=self.process_with_ollama, 
                        args=(self.captured_frame.copy(), question), 
                        daemon=True).start()
    
    def display_captured_image(self):
        """é¡¯ç¤ºæ‹æ”çš„ç…§ç‰‡"""
        if self.captured_frame is not None:
            display_frame = cv2.resize(self.captured_frame, (400, 300))
            display_frame = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
            
            pil_image = Image.fromarray(display_frame)
            photo = ImageTk.PhotoImage(pil_image)
            
            self.captured_image_label.config(image=photo, text="")
            self.captured_image_label.image = photo
    
    def process_with_ollama(self, frame, question):
        """è™•ç†åœ–åƒä¸¦å„²å­˜åˆ°å‘é‡è³‡æ–™åº«ï¼ˆå½±åƒç›´æ¥å„²å­˜ï¼‰"""
        try:
            # ğŸ”¥ é—œéµè®ŠåŒ–ï¼šå°‡å½±åƒè½‰æ›ç‚º base64 ç”¨æ–¼å„²å­˜
            frame_base64, image_size = self.image_to_base64(frame, quality=85, max_size=800)
            
            # è½‰æ›åœ–åƒç”¨æ–¼ API å‘¼å«ï¼ˆè¼ƒå°å°ºå¯¸ï¼‰
            pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            
            # é©åº¦ç¸®æ”¾ç”¨æ–¼ API
            if max(pil_image.size) > 512:
                ratio = 512 / max(pil_image.size)
                new_size = tuple(int(dim * ratio) for dim in pil_image.size)
                pil_image = pil_image.resize(new_size, Image.Resampling.LANCZOS)
            
            # è½‰æ›ç‚º base64 ç”¨æ–¼ API
            buffer = io.BytesIO()
            pil_image.save(buffer, format='PNG')
            img_base64_api = base64.b64encode(buffer.getvalue()).decode()
            
            # å‘¼å« Ollama API
            temperature = self.temperature_var.get()
            payload = {
                "model": self.current_model,
                "prompt": question,
                "images": [img_base64_api],
                "stream": False,
                "options": {
                    "temperature": temperature
                }
            }
            
            self.log_message(f"æ­£åœ¨å‘¼å« Ollama API (Temperature: {temperature:.2f})...")
            self.log_message("â° LLaVA-Phi3 é¦–æ¬¡æ¨ç†è¼ƒæ…¢ï¼Œè«‹è€å¿ƒç­‰å¾…...")
            
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=payload,
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                answer = result.get("response", "ç„¡æ³•ç²å¾—å›ç­”")
                
                if answer and answer.strip():
                    self.log_message(f"AI å›ç­”: {answer}")
                    
                    # ğŸ”¥ é‡é»ï¼šå„²å­˜åˆ°å‘é‡è³‡æ–™åº«ï¼ˆå½±åƒç›´æ¥å„²å­˜ç‚º base64ï¼‰
                    if frame_base64:
                        self.save_conversation_to_vector_db(
                            question=question,
                            answer=answer,
                            frame_base64=frame_base64,  # å®Œæ•´è³ªé‡çš„å½±åƒ
                            image_size=image_size,
                            metadata={
                                "api_image_size": f"{pil_image.size[0]}x{pil_image.size[1]}",
                                "storage_image_size": f"{image_size[0]}x{image_size[1]}" if image_size else "unknown",
                                "response_length": len(answer),
                                "api_call_success": True,
                                "storage_method": "embedded_base64"
                            }
                        )
                    
                else:
                    self.log_message("âš ï¸ AI å›ç­”ç‚ºç©ºï¼Œè«‹é‡è©¦")
            else:
                self.log_message(f"API éŒ¯èª¤ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
                self.log_message(f"éŒ¯èª¤å…§å®¹: {response.text}")
            
            self.is_analyzing = False
            self.root.after(0, lambda: self.status_label.config(text="åˆ†æå®Œæˆ"))
            
        except requests.exceptions.Timeout:
            self.log_message("â° è«‹æ±‚è¶…æ™‚ - LLaVA-Phi3 é¦–æ¬¡æ¨ç†éœ€è¦è¼ƒé•·æ™‚é–“")
            self.log_message("ğŸ’¡ æç¤ºï¼šç¬¬ä¸€æ¬¡æ¨ç†æœƒè¼ƒæ…¢ï¼Œå¾ŒçºŒæœƒè®Šå¿«")
            self.log_message("ğŸ”„ è«‹ç¨å¾Œé‡è©¦ï¼Œæˆ–å˜—è©¦è¼ƒç°¡å–®çš„å•é¡Œ")
            self.is_analyzing = False
            self.root.after(0, lambda: self.status_label.config(text="é¦–æ¬¡æ¨ç†è¶…æ™‚ï¼Œè«‹é‡è©¦"))
            
        except Exception as e:
            self.log_message(f"è™•ç†éŒ¯èª¤: {str(e)}")
            self.is_analyzing = False
            self.root.after(0, lambda: self.status_label.config(text="è™•ç†å¤±æ•—"))
    
    def log_message(self, message):
        """è¨˜éŒ„è¨Šæ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        formatted_message = f"[{timestamp}] {message}\n"
        
        self.root.after(0, self._update_text, formatted_message)
    
    def _update_text(self, message):
        """æ›´æ–°æ–‡å­—å€åŸŸ"""
        self.result_text.insert(tk.END, message)
        self.result_text.see(tk.END)
    
    def run(self):
        """é‹è¡Œæ‡‰ç”¨ç¨‹å¼"""
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)
        self.root.mainloop()
    
    def on_closing(self):
        """é—œé–‰æ‡‰ç”¨ç¨‹å¼"""
        self.stop_camera()
        self.root.destroy()

def main():
    """ä¸»å‡½æ•¸"""
    print("VLM ç³»çµ± + å‘é‡è³‡æ–™åº« (å½±åƒå…§åµŒç‰ˆ)")
    print("=" * 50)
    print("âœ¨ ä½¿ç”¨ LLaVA-Phi3:latest æ¨¡å‹")
    print("ğŸ–¼ï¸ å½±åƒç›´æ¥å„²å­˜åœ¨å‘é‡è³‡æ–™åº«ä¸­")
    print("ğŸ’¾ ç„¡éœ€ç®¡ç†æª”æ¡ˆç³»çµ±ï¼Œçµ±ä¸€å„²å­˜")
    print("ğŸ” æ”¯æ´å°è©±æœå°‹å’Œå½±åƒæª¢è¦–")
    print("ğŸŒ æ”¯æ´ä¸­è‹±æ–‡å•ç­”")
    print("\nğŸ“¦ éœ€è¦çš„æœå‹™:")
    print("1. ollama pull llava-phi3:latest")
    print("2. docker run -p 6333:6333 qdrant/qdrant")
    print("=" * 50)
    
    try:
        app = VLMWithEmbeddedImages()
        app.run()
    except KeyboardInterrupt:
        print("\nç¨‹å¼å·²åœæ­¢")

if __name__ == "__main__":
    main()
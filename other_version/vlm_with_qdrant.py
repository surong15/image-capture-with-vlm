#!/usr/bin/env python3
"""
VLM + å‘é‡è³‡æ–™åº«æ•´åˆç‰ˆæœ¬
æ¯æ¬¡å•ç­”éƒ½æœƒè‡ªå‹•å„²å­˜åˆ° Qdrant å‘é‡è³‡æ–™åº«ä¸­ï¼Œä¸¦å°‡åœ–ç‰‡å„²å­˜åœ¨é›»è…¦ä¸Š
DB = vlm_conversations
"""

import cv2
import numpy as np
from PIL import Image, ImageTk
import requests
import base64
import io
import json
import tkinter as tk
from tkinter import ttk, scrolledtext, messagebox
from datetime import datetime
import threading
import time
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
from sentence_transformers import SentenceTransformer
import uuid
import os

class SimpleWorkingVLM:
    def __init__(self):
        self.cap = None
        self.current_frame = None
        self.captured_frame = None
        self.is_running = False
        self.ollama_url = "http://localhost:11434"
        self.live_video_label = None
        self.captured_image_label = None
        self.update_video_flag = True
        self.is_analyzing = False
        self.current_model = None  # å°‡è‡ªå‹•æª¢æ¸¬å¯ç”¨æ¨¡å‹
        
        self.setup_gui()
        self.init_vector_db()
    
    def init_vector_db(self):
        """åˆå§‹åŒ–å‘é‡è³‡æ–™åº«"""
        try:
            self.qdrant_client = QdrantClient("localhost", port=6333)
            self.encoder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            
            # å»ºç«‹VLMå°ˆç”¨é›†åˆ
            self.vlm_collection = "vlm_conversations"
            
            # æª¢æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨å‰‡å»ºç«‹
            collections = self.qdrant_client.get_collections()
            collection_names = [c.name for c in collections.collections]
            
            if self.vlm_collection not in collection_names:
                self.qdrant_client.create_collection(
                    collection_name=self.vlm_collection,
                    vectors_config=VectorParams(size=384, distance=Distance.COSINE)
                )
            
            # å»ºç«‹åœ–ç‰‡å„²å­˜è³‡æ–™å¤¾
            self.images_dir = "vlm_images"
            os.makedirs(self.images_dir, exist_ok=True)
            
            print("âœ… å‘é‡è³‡æ–™åº«åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ å‘é‡è³‡æ–™åº«åˆå§‹åŒ–å¤±æ•—: {e}")
            self.qdrant_client = None
    
    def save_image(self, frame):
        """å„²å­˜åœ–ç‰‡ä¸¦è¿”å›è·¯å¾‘"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"vlm_image_{timestamp}_{uuid.uuid4().hex[:8]}.jpg"
            image_path = os.path.join(self.images_dir, filename)
            
            # è½‰æ›ä¸¦å„²å­˜åœ–ç‰‡
            pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            pil_image.save(image_path, "JPEG", quality=85)
            
            return image_path
            
        except Exception as e:
            print(f"âŒ åœ–ç‰‡å„²å­˜å¤±æ•—: {e}")
            return None
        
    def save_conversation_to_vector_db(self, question, answer, image_path):
        """å°‡å°è©±å„²å­˜åˆ°å‘é‡è³‡æ–™åº«"""
        if not self.qdrant_client:
            return
        
        try:
            timestamp = datetime.now()
            
            # å»ºç«‹åŒ…å«å®Œæ•´å°è©±çš„æ–‡æœ¬
            conversation_text = f"å•é¡Œ: {question}\nå›ç­”: {answer}"
            
            # å»ºç«‹å…ƒæ•¸æ“š
            metadata = {
                "question": question,
                "answer": answer,
                "image_path": image_path,
                "timestamp": timestamp.isoformat(),
                "date": timestamp.strftime("%Y-%m-%d"),
                "time": timestamp.strftime("%H:%M:%S"),
                "model": self.current_model or "unknown",
                "temperature": self.temperature_var.get()
            }
            
            # å°‡å°è©±æ–‡æœ¬å‘é‡åŒ–
            vector = self.encoder.encode([conversation_text])[0]
            
            # å»ºç«‹é»æ•¸æ“š
            point = PointStruct(
                id=str(uuid.uuid4()),
                vector=vector.tolist(),
                payload={
                    "content": conversation_text,
                    **metadata
                }
            )
            
            # ä¸Šå‚³åˆ° Qdrant
            self.qdrant_client.upsert(
                collection_name=self.vlm_collection,
                points=[point]
            )
            
            self.log_message(f"ğŸ’¾ å°è©±å·²å„²å­˜åˆ°å‘é‡è³‡æ–™åº«")
            
        except Exception as e:
            print(f"âŒ å„²å­˜å°è©±å¤±æ•—: {e}")  

    def setup_gui(self):
        """è¨­ç½®é›™ç•«é¢é¡¯ç¤ºçš„åœ–å½¢ç•Œé¢"""
        self.root = tk.Tk()
        self.root.title("VLM ç³»çµ± - LLaVA-Phi3 ç‰ˆæœ¬")
        self.root.geometry("1200x800")
        
        # ä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # å·¦å´ - å½±åƒé¡¯ç¤ºå€åŸŸ
        image_container = ttk.Frame(main_frame)
        image_container.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(0, 10))
        
        # å³æ™‚å½±åƒå€åŸŸ
        live_frame = ttk.LabelFrame(image_container, text="ğŸ“¹ å³æ™‚å½±åƒ")
        live_frame.pack(fill=tk.BOTH, expand=True, pady=(0, 5))
        
        self.live_video_label = ttk.Label(live_frame, text="å³æ™‚ç›¸æ©Ÿç•«é¢\né»æ“Šã€Œé–‹å§‹ç›¸æ©Ÿã€å•Ÿå‹•")
        self.live_video_label.pack(expand=True, padx=10, pady=10)
        
        # åˆ†æç…§ç‰‡å€åŸŸ
        captured_frame = ttk.LabelFrame(image_container, text="ğŸ“¸ æ­£åœ¨åˆ†æçš„ç…§ç‰‡")
        captured_frame.pack(fill=tk.BOTH, expand=True, pady=(5, 0))
        
        self.captured_image_label = ttk.Label(captured_frame, text="å°šæœªæ‹æ”ç…§ç‰‡\né»æ“Šã€Œæ‹ç…§åˆ†æã€é–‹å§‹")
        self.captured_image_label.pack(expand=True, padx=10, pady=10)
        
        # å³å´ - æ§åˆ¶å’Œçµæœå€åŸŸ
        right_frame = ttk.Frame(main_frame, width=400)
        right_frame.pack(side=tk.RIGHT, fill=tk.BOTH, padx=(10, 0))
        right_frame.pack_propagate(False)
        
        # ç³»çµ±ç‹€æ…‹
        status_frame = ttk.LabelFrame(right_frame, text="ç³»çµ±ç‹€æ…‹")
        status_frame.pack(fill=tk.X, pady=(0, 10))
        
        self.ollama_status = ttk.Label(status_frame, text="Ollama ç‹€æ…‹: æª¢æŸ¥ä¸­...")
        self.ollama_status.pack(anchor=tk.W, padx=5, pady=3)
        
        # ç›¸æ©Ÿæ§åˆ¶
        camera_frame = ttk.LabelFrame(right_frame, text="ç›¸æ©Ÿæ§åˆ¶")
        camera_frame.pack(fill=tk.X, pady=(0, 10))
        
        camera_btn_frame = ttk.Frame(camera_frame)
        camera_btn_frame.pack(fill=tk.X, padx=5, pady=5)
        
        self.start_btn = ttk.Button(camera_btn_frame, text="é–‹å§‹ç›¸æ©Ÿ", command=self.start_camera)
        self.start_btn.pack(side=tk.LEFT, padx=(0, 5))
        
        self.stop_btn = ttk.Button(camera_btn_frame, text="åœæ­¢ç›¸æ©Ÿ", command=self.stop_camera, state=tk.DISABLED)
        self.stop_btn.pack(side=tk.LEFT, padx=(0, 5))
        
        self.capture_btn = ttk.Button(camera_btn_frame, text="æ‹ç…§åˆ†æ", command=self.capture_and_ask, state=tk.DISABLED)
        self.capture_btn.pack(side=tk.RIGHT)
        
        # å•é¡Œè¼¸å…¥
        question_frame = ttk.LabelFrame(right_frame, text="å•é¡Œè¼¸å…¥")
        question_frame.pack(fill=tk.X, pady=(0, 10))
        
        self.question_entry = tk.Text(question_frame, height=3, wrap=tk.WORD)
        self.question_entry.pack(fill=tk.X, padx=5, pady=5)
        self.question_entry.insert(tk.END, "è«‹æè¿°é€™å¼µåœ–ç‰‡ã€‚")
        
        # å¿«é€Ÿå•é¡Œï¼ˆé‡å° LLaVA-Phi3 å„ªåŒ–ï¼Œæ”¯æ´ä¸­è‹±æ–‡ï¼‰
        quick_frame = ttk.Frame(question_frame)
        quick_frame.pack(fill=tk.X, padx=5, pady=(5, 0))
        
        quick_questions = [
            ("æœ‰ä»€éº¼ï¼Ÿ", "é€™å¼µåœ–ç‰‡è£¡æœ‰ä»€éº¼ï¼Ÿ"),
            ("è©³ç´°æè¿°", "è«‹è©³ç´°æè¿°é€™å¼µåœ–ç‰‡çš„å…§å®¹ã€‚"),
            ("What's this?", "What do you see in this image?"),
            ("é¡è‰²ï¼Ÿ", "ä¸»è¦æœ‰ä»€éº¼é¡è‰²ï¼Ÿ"),
            ("å¹¾å€‹äººï¼Ÿ", "åœ–ç‰‡ä¸­æœ‰å¹¾å€‹äººï¼Ÿ"),
            ("Describe", "Describe this image in detail.")
        ]
        
        for i, (short_text, full_question) in enumerate(quick_questions):
            btn = ttk.Button(quick_frame, text=short_text, 
                           command=lambda q=full_question: self.set_question(q))
            btn.grid(row=i//3, column=i%3, padx=2, pady=2, sticky="ew")
        
        for i in range(3):
            quick_frame.columnconfigure(i, weight=1)
        
        # çµæœé¡¯ç¤º
        result_frame = ttk.LabelFrame(right_frame, text="AI å›ç­”")
        result_frame.pack(fill=tk.BOTH, expand=True)
        
        self.result_text = scrolledtext.ScrolledText(result_frame, height=15, wrap=tk.WORD)
        self.result_text.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        # æ¨¡å‹åƒæ•¸
        options_frame = ttk.LabelFrame(right_frame, text="æ¨¡å‹åƒæ•¸")
        options_frame.pack(fill=tk.X, pady=(0, 10))
        
        temp_label = ttk.Label(options_frame, text="Temperature (0.0-1.0):")
        temp_label.pack(side=tk.LEFT, padx=(5,0))
        
        self.temperature_var = tk.DoubleVar(value=0.2) # é è¨­ä½æº«ä»¥æ¸›å°‘å¹»è¦º
        
        self.temp_value_label = ttk.Label(options_frame, text=f"{self.temperature_var.get():.2f}", width=4)
        self.temp_value_label.pack(side=tk.RIGHT, padx=(0,5))

        self.temperature_scale = ttk.Scale(options_frame, from_=0.0, to=1.0, 
                                          orient=tk.HORIZONTAL, variable=self.temperature_var,
                                          command=self.update_temp_label)
        self.temperature_scale.pack(fill=tk.X, expand=True, padx=5)

        # ç‹€æ…‹åˆ—
        self.status_label = ttk.Label(self.root, text="æº–å‚™å°±ç·’")
        self.status_label.pack(fill=tk.X, side=tk.BOTTOM, padx=10, pady=5)
        
        # å»¶é²å•Ÿå‹• Ollama é€£ç·šæª¢æŸ¥ï¼Œç¢ºä¿ mainloop å·²å•Ÿå‹•
        self.root.after(100, self.check_ollama_connection)
    
    def set_question(self, question):
        """è¨­ç½®å•é¡Œ"""
        self.question_entry.delete(1.0, tk.END)
        self.question_entry.insert(tk.END, question)
    
    def update_temp_label(self, value):
        """æ›´æ–°æº«åº¦é¡¯ç¤ºæ¨™ç±¤"""
        self.temp_value_label.config(text=f"{float(value):.2f}")
    
    def check_ollama_connection(self):
        """æª¢æŸ¥ Ollama é€£æ¥ç‹€æ…‹"""
        def check_in_background():
            try:
                response = requests.get(f"{self.ollama_url}/api/tags", timeout=3)
                if response.status_code == 200:
                    models = response.json().get("models", [])
                    model_names = [model.get("name", "") for model in models]
                    
                    # å„ªå…ˆæª¢æŸ¥ llava-phi3:latest
                    target_model = "llava-phi3:latest"
                    
                    if any(target_model in name for name in model_names):
                        self.current_model = target_model
                        self.root.after(0, lambda: self.ollama_status.config(
                            text="âœ… Ollama + LLaVA-Phi3 å¯ç”¨", foreground="green"))
                        self.root.after(0, lambda: self.capture_btn.config(state=tk.NORMAL))
                        self.log_message(f"ä½¿ç”¨æ¨¡å‹: {self.current_model}")
                    else:
                        # æª¢æŸ¥æ˜¯å¦æœ‰å…¶ä»– llava-phi3 ç‰ˆæœ¬
                        phi3_models = [name for name in model_names if "llava-phi3" in name]
                        if phi3_models:
                            self.current_model = phi3_models[0]
                            self.root.after(0, lambda: self.ollama_status.config(
                                text=f"âœ… Ollama + {self.current_model} å¯ç”¨", foreground="green"))
                            self.root.after(0, lambda: self.capture_btn.config(state=tk.NORMAL))
                            self.log_message(f"ä½¿ç”¨æ¨¡å‹: {self.current_model}")
                        else:
                            self.root.after(0, lambda: self.ollama_status.config(
                                text="âš ï¸ éœ€è¦å®‰è£ LLaVA-Phi3", foreground="orange"))
                            self.suggest_install_phi3()
                else:
                    raise Exception("æœå‹™ä¸å¯ç”¨")
                    
            except Exception:
                self.root.after(0, lambda: self.ollama_status.config(
                    text="âŒ Ollama æœªé‹è¡Œ", foreground="red"))
                self.log_message("è«‹åŸ·è¡Œ: ollama serve")
        
        threading.Thread(target=check_in_background, daemon=True).start()
    
    def suggest_install_phi3(self):
        """å»ºè­°å®‰è£ LLaVA-Phi3"""
        message = """éœ€è¦å®‰è£ LLaVA-Phi3 æ¨¡å‹ï¼

è«‹åœ¨çµ‚ç«¯åŸ·è¡Œï¼š
ollama pull llava-phi3:latest

LLaVA-Phi3 ç‰¹è‰²ï¼š
âœ¨ åŸºæ–¼ Microsoft Phi-3ï¼Œæ•ˆèƒ½å„ªç§€
ğŸ’¾ è¨˜æ†¶é«”éœ€æ±‚è¼ƒä½ï¼Œé©åˆ 8GB MacBook
ğŸš€ æ¨ç†é€Ÿåº¦å¿«
ğŸŒ æ”¯æ´å¤šèªè¨€å›ç­”

å®‰è£å®Œæˆå¾Œé‡æ–°å•Ÿå‹•ç¨‹å¼ã€‚"""
        
        self.log_message(message)
    
    def start_camera(self):
        """é–‹å§‹ç›¸æ©Ÿ"""
        try:
            self.cap = cv2.VideoCapture(0)
            if not self.cap.isOpened():
                raise Exception("ç„¡æ³•é–‹å•Ÿç›¸æ©Ÿ")
            
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            
            self.is_running = True
            self.update_video_flag = True
            
            self.video_thread = threading.Thread(target=self.update_live_video)
            self.video_thread.daemon = True
            self.video_thread.start()
            
            self.start_btn.config(state=tk.DISABLED)
            self.stop_btn.config(state=tk.NORMAL)
            self.capture_btn.config(state=tk.NORMAL)
            
            self.status_label.config(text="ç›¸æ©Ÿå·²å•Ÿå‹•")
            self.log_message("ç›¸æ©Ÿå•Ÿå‹•æˆåŠŸ")
            
        except Exception as e:
            messagebox.showerror("éŒ¯èª¤", f"ç›¸æ©Ÿå•Ÿå‹•å¤±æ•—: {str(e)}")
    
    def stop_camera(self):
        """åœæ­¢ç›¸æ©Ÿ"""
        self.is_running = False
        self.update_video_flag = False
        
        if self.cap:
            self.cap.release()
        
        self.live_video_label.config(image="", text="ç›¸æ©Ÿå·²åœæ­¢")
        
        self.start_btn.config(state=tk.NORMAL)
        self.stop_btn.config(state=tk.DISABLED)
        self.capture_btn.config(state=tk.DISABLED)
        
        self.status_label.config(text="ç›¸æ©Ÿå·²åœæ­¢")
        self.log_message("ç›¸æ©Ÿå·²åœæ­¢")
    
    def update_live_video(self):
        """æ›´æ–°å³æ™‚å½±åƒ"""
        while self.is_running and self.update_video_flag:
            try:
                ret, frame = self.cap.read()
                if ret:
                    self.current_frame = frame.copy()
                    
                    display_frame = cv2.resize(frame, (400, 300))
                    display_frame = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
                    
                    pil_image = Image.fromarray(display_frame)
                    photo = ImageTk.PhotoImage(pil_image)
                    
                    self.root.after(0, self._update_live_video_label, photo)
                    
                    time.sleep(0.033)  # 30 FPS
                    
            except Exception as e:
                print(f"å½±åƒæ›´æ–°éŒ¯èª¤: {e}")
                break
    
    def _update_live_video_label(self, photo):
        """æ›´æ–°å³æ™‚å½±åƒæ¨™ç±¤"""
        if self.live_video_label and self.update_video_flag:
            self.live_video_label.config(image=photo, text="")
            self.live_video_label.image = photo
    
    def capture_and_ask(self):
        """æ‹ç…§ä¸¦æå•"""
        if self.current_frame is None:
            messagebox.showwarning("è­¦å‘Š", "æ²’æœ‰å¯ç”¨çš„å½±åƒ")
            return
        
        question = self.question_entry.get(1.0, tk.END).strip()
        if not question:
            question = "è«‹æè¿°é€™å¼µåœ–ç‰‡ã€‚"
        
        self.captured_frame = self.current_frame.copy()
        self.display_captured_image()
        
        self.is_analyzing = True
        self.status_label.config(text="AI åˆ†æä¸­...")
        
        self.log_message(f"å•é¡Œ: {question}")
        
        threading.Thread(target=self.process_with_ollama, 
                        args=(self.captured_frame.copy(), question), 
                        daemon=True).start()
    
    def display_captured_image(self):
        """é¡¯ç¤ºæ‹æ”çš„ç…§ç‰‡"""
        if self.captured_frame is not None:
            display_frame = cv2.resize(self.captured_frame, (400, 300))
            display_frame = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
            
            pil_image = Image.fromarray(display_frame)
            photo = ImageTk.PhotoImage(pil_image)
            
            self.captured_image_label.config(image=photo, text="")
            self.captured_image_label.image = photo
    
    def process_with_ollama(self, frame, question):
        """è™•ç†åœ–åƒä¸¦å„²å­˜åˆ°å‘é‡è³‡æ–™åº«"""
        try:
            # å…ˆå„²å­˜åœ–ç‰‡
            image_path = self.save_image(frame)
            # è½‰æ›åœ–åƒï¼ˆä¿æŒæœ€ç°¡å–®çš„è™•ç†ï¼‰
            pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            
            # é©åº¦ç¸®æ”¾ï¼ˆä¸è¦å¤ªå°ï¼‰
            if max(pil_image.size) > 512:
                ratio = 512 / max(pil_image.size)
                new_size = tuple(int(dim * ratio) for dim in pil_image.size)
                pil_image = pil_image.resize(new_size, Image.Resampling.LANCZOS)
            
            # è½‰æ›ç‚º base64
            buffer = io.BytesIO()
            pil_image.save(buffer, format='PNG')
            img_base64 = base64.b64encode(buffer.getvalue()).decode()
            
            # ä½¿ç”¨æª¢æ¸¬åˆ°çš„æ¨¡å‹
            temperature = self.temperature_var.get()
            payload = {
                "model": self.current_model,
                "prompt": question,
                "images": [img_base64],
                "stream": False,
                "options": {
                    "temperature": temperature
                }
            }
            
            self.log_message(f"æ­£åœ¨å‘¼å« Ollama API (Temperature: {temperature:.2f})...")
            self.log_message("â° LLaVA-Phi3 é¦–æ¬¡æ¨ç†è¼ƒæ…¢ï¼Œè«‹è€å¿ƒç­‰å¾…...")
            
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=payload,
                timeout=120  # å¢åŠ åˆ° 2 åˆ†é˜è¶…æ™‚
            )
            
            if response.status_code == 200:
                result = response.json()
                answer = result.get("response", "ç„¡æ³•ç²å¾—å›ç­”")
                
                if answer and answer.strip():
                    self.log_message(f"AI å›ç­”: {answer}")
                    # ğŸ”¥ æ–°å¢ï¼šå„²å­˜åˆ°å‘é‡è³‡æ–™åº«
                    if image_path:
                        self.save_conversation_to_vector_db(question, answer, image_path)
                else:
                    self.log_message("âš ï¸ AI å›ç­”ç‚ºç©ºï¼Œè«‹é‡è©¦")
            else:
                self.log_message(f"API éŒ¯èª¤ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
                self.log_message(f"éŒ¯èª¤å…§å®¹: {response.text}")
            
            self.is_analyzing = False
            self.root.after(0, lambda: self.status_label.config(text="åˆ†æå®Œæˆ"))
            
        except requests.exceptions.Timeout:
            self.log_message("â° è«‹æ±‚è¶…æ™‚ - LLaVA-Phi3 é¦–æ¬¡æ¨ç†éœ€è¦è¼ƒé•·æ™‚é–“")
            self.log_message("ğŸ’¡ æç¤ºï¼šç¬¬ä¸€æ¬¡æ¨ç†æœƒè¼ƒæ…¢ï¼Œå¾ŒçºŒæœƒè®Šå¿«")
            self.log_message("ğŸ”„ è«‹ç¨å¾Œé‡è©¦ï¼Œæˆ–å˜—è©¦è¼ƒç°¡å–®çš„å•é¡Œ")
            self.is_analyzing = False
            self.root.after(0, lambda: self.status_label.config(text="é¦–æ¬¡æ¨ç†è¶…æ™‚ï¼Œè«‹é‡è©¦"))
            
        except Exception as e:
            self.log_message(f"è™•ç†éŒ¯èª¤: {str(e)}")
            self.is_analyzing = False
            self.root.after(0, lambda: self.status_label.config(text="è™•ç†å¤±æ•—"))
    
    def log_message(self, message):
        """è¨˜éŒ„è¨Šæ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        formatted_message = f"[{timestamp}] {message}\n"
        
        self.root.after(0, self._update_text, formatted_message)
    
    def _update_text(self, message):
        """æ›´æ–°æ–‡å­—å€åŸŸ"""
        self.result_text.insert(tk.END, message)
        self.result_text.see(tk.END)
    
    def run(self):
        """é‹è¡Œæ‡‰ç”¨ç¨‹å¼"""
        self.root.protocol("WM_DELETE_WINDOW", self.on_closing)
        self.root.mainloop()
    
    def on_closing(self):
        """é—œé–‰æ‡‰ç”¨ç¨‹å¼"""
        self.stop_camera()
        self.root.destroy()

def main():
    """ä¸»å‡½æ•¸"""
    print("VLM ç³»çµ± - LLaVA-Phi3 ç‰ˆæœ¬")
    print("=" * 40)
    print("âœ¨ ä½¿ç”¨ LLaVA-Phi3:latest æ¨¡å‹")
    print("ğŸ’¾ è¨˜æ†¶é«”éœ€æ±‚ä½ï¼Œé©åˆ 8GB MacBook Pro")
    print("ğŸŒ æ”¯æ´ä¸­è‹±æ–‡å•ç­”")
    print("ğŸš€ æ¨ç†é€Ÿåº¦å¿«")
    print("\nğŸ“¦ å®‰è£æŒ‡ä»¤:")
    print("ollama pull llava-phi3:latest")
    print("=" * 40)
    
    try:
        app = SimpleWorkingVLM()
        app.run()
    except KeyboardInterrupt:
        print("\nç¨‹å¼å·²åœæ­¢")

if __name__ == "__main__":
    main()